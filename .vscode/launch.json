{
    "version": "0.2.0",
    "configurations": [
      {
        "name": "Python: Debug example_chat_completion.py with torchrun",
        "type": "python",
        "request": "launch",
        "program": "${workspaceFolder}/.venv/bin/torchrun",
        "console": "integratedTerminal",
        "env": {
          "PYTORCH_ENABLE_MPS_FALLBACK": "1",
        },
        "args": [
          "--nproc_per_node",
          "8",
          "${workspaceFolder}/example_chat_completion.py",
          "--max_seq_len",
          "1024",
          "--max_batch_size",
          "16",
          "--temperature",
          "0",
          "--top_p",
          "0.95",
          "--ckpt_dir",
          "model_weights/Smaug-Llama-3-70B-Instruct/",
          "--tokenizer_path",
          "model_weights/Smaug-Llama-3-70B-Instruct/tokenizer.model"
        ]
      }
    ]
  }